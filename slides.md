# What is Drift?
## â€œWhen the world changes, but the model doesnâ€™t.â€
Drift is a change in the joint data distribution P(X,Y) over time.

--

# Types of Drift
## By what changes

<img src="figures/real_virtual_drift.png" alt="Drift types" style="width:70%">

Note:

Î‘Ï‚ Ï†Î±Î½Ï„Î±ÏƒÏ„Î¿ÏÎ¼Îµ Î­Î½Î± Î¼Î¿Î½Ï„Î­Î»Î¿ Ï€Î¿Ï… Î±Î½Î¹Ï‡Î½ÎµÏÎµÎ¹ Î±Ï€Î¬Ï„Î· ÏƒÎµ ÏƒÏ…Î½Î±Î»Î»Î±Î³Î­Ï‚.
Î‘Î½ Î±Î»Î»Î¬Î¾ÎµÎ¹ Î¼ÏŒÎ½Î¿ Î¿ Ï„ÏÏŒÏ€Î¿Ï‚ Ï€Î¿Ï… Î¼Î¿Î¹Î¬Î¶Î¿Ï…Î½ Î¿Î¹ ÏƒÏ…Î½Î±Î»Î»Î±Î³Î­Ï‚ â€” Î³Î¹Î± Ï€Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±, Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ online Î±Î³Î¿ÏÎ­Ï‚ Ï„Î± Î§ÏÎ¹ÏƒÏ„Î¿ÏÎ³ÎµÎ½Î½Î± â€” Î­Ï‡Î¿Ï…Î¼Îµ virtual drift: Î±Î»Î»Î¬Î¶ÎµÎ¹ Î· ÎºÎ±Ï„Î±Î½Î¿Î¼Î® Ï„Ï‰Î½ ÎµÎ¹ÏƒÏŒÎ´Ï‰Î½, ÏŒÏ‡Î¹ Î· ÏƒÏ‡Î­ÏƒÎ· Î¼Îµ Ï„Î·Î½ Î±Ï€Î¬Ï„Î·.
Î‘Î½ ÏŒÎ¼Ï‰Ï‚ Î¿Î¹ Î±Ï€Î±Ï„ÎµÏÎ½ÎµÏ‚ Î±Î»Î»Î¬Î¾Î¿Ï…Î½ ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® ÎºÎ±Î¹ ÎºÎ¬Î½Î¿Ï…Î½ Î¼Î¹ÎºÏÏŒÏ„ÎµÏÎµÏ‚, Ï€Î¹Î¿ â€œÎºÎ±Î½Î¿Î½Î¹ÎºÎ­Ï‚â€ ÏƒÏ…Î½Î±Î»Î»Î±Î³Î­Ï‚, Î±Î»Î»Î¬Î¶ÎµÎ¹ Î· ÏƒÏ‡Î­ÏƒÎ· Î¼ÎµÏ„Î±Î¾Ï ÎµÎ¹ÏƒÏŒÎ´Î¿Ï… ÎºÎ±Î¹ ÎµÎ¾ÏŒÎ´Î¿Ï… â€” Î±Ï…Ï„ÏŒ ÎµÎ¯Î½Î±Î¹ actual drift.
ÎšÎ±Î¹ Î±Î½ Î±Î»Î»Î¬Î¾Î¿Ï…Î½ ÎºÎ±Î¹ Î¿Î¹ Î´ÏÎ¿ Ï€Î»ÎµÏ…ÏÎ­Ï‚, Î´Î·Î»Î±Î´Î® ÎºÎ±Î¹ Î· ÏƒÏ…Î¼Ï€ÎµÏÎ¹Ï†Î¿ÏÎ¬ Ï„Ï‰Î½ Ï‡ÏÎ·ÏƒÏ„ÏÎ½ ÎºÎ±Î¹ Ï„Ï‰Î½ Î±Ï€Î±Ï„ÎµÏÎ½Ï‰Î½, Ï„ÏŒÏ„Îµ Î­Ï‡Î¿Ï…Î¼Îµ concept drift.

--

# Types of Drift
## By how it changes

<img src="figures/drift_classes.png" alt="Drift types_in_time" style="width:70%">

--

# Why do we Detect Drift?
- Detect changes in data or concept $\rightarrow$ model adaptation (e.g. retraining)
- Ensure the model remains accurate and relevant as the world changes

---

# How do we Detect Drift?

Process called drift detection which monitors a system over time to spot changes in its behavior or performance.

Note: It helps identify when things start to deviate from expected standardsâ€”like a model becoming less accurateâ€”so that adjustments can be made to keep quality high.

--

# Supervised Drift Detection

Algorithms assume that true labels are available for at least some portion of the incoming data in order for the model to be trained

--

# Semi-supervised Drift Detection

These algorithms useÂ **both features and labels**Â when labels areÂ **partially available**

Note:

Labels are often delayed, sparse, or costly to obtain

--

# Unsupervised Drift Detection

Unsupervised drift detection algorithms relyÂ **only on the input features**Â $X$

---

# Drift Detection Categories

--

# Block-based Methods
## â€œAnalyze the story in chaptersâ€

Divide the data stream into large, fixed-size blocks.
Each block is treated as a complete statistical unit, analyzed individually or compared with previous blocks.

## How it works:

- Each block represents a full distribution snapshot.
- Drift can be detected within a block or between consecutive blocks.

## Pros:

- Robust to noise.
- Can detect multiple drifts within a block.

## Cons:

- Slow reaction time (waits for block completion)
- Computationally heavy

Note:

Examples: Kernel MMD, Wasserstein-based detectors.

## Key distinction:

Block-based methods use large, mostly non-overlapping windows analyzed as independent data segments, not as continuously moving windows.

--

# Batch-based Methods
## â€œCompare yesterday and todayâ€

They keep two smaller windows of data:
- A reference window (past concept).
- A detection window (recent data).

## How it works:

- Windows can be fixed, sliding, or adaptive.
- When differences exceed a threshold $\rightarrow$ drift detected.

## Pros:

- Detects both gradual and sudden drifts.

## Cons:

- Must wait for both windows to fill.
- Choice of window size impacts sensitivity.

Note:

They compare distributions (e.g., KS test) to check if the new batch differs significantly from the old one

Examples: NN-DVI, SQSI.

## Key distinction:

Batch-based methods rely on explicit comparison between two consecutive windows, focusing on contrast between past and present data.

--

# Online-based Methods
## â€œReact as the words changeâ€

They detect drift continuously, updating statistics as each instance arrives.

## How it works:

- Use sliding or adaptive windows that move forward with every new data point.

- Apply incremental statistics or hypothesis tests in real time.

## Pros:

- Fastest detection, reacts immediately to change.

## Cons:

- Sensitive to noise, prone to false alarms

Note:

Examples: ADWIN, DSDD, Page-Hinkley, SAND.

## Key distinction:

Online-based methods differ mainly in timing â€” they update continuously per instance, unlike batch or block methods that wait for windows to fill.

--

# Meta-statistic-based Methods
## â€œWatch the watcherâ€

They donâ€™t analyze raw data directly, they monitor how a model behaves.

## How it works:

- Monitors metrics such as error rate or loss
- Apply a statistical test (e.g., ADWIN) to detect significant changes in these metrics.

## Pros:

- Model-agnostic, works with any learner.
- Can function even without labels (unsupervised drift).

## Cons:

- Indirect, relies on model accuracy which may miss subtle (virtual) drifts

Note:

Model-agnostic means:

1. Doesnâ€™t assume a specific data distribution,

2. Compares windows of data, and

3. Tests for statistical independence between features and labels (or between time and data)

Examples: Model + ADWIN, loss-based drift detection, reconstruction error drift detection.

## Key distinction:

Meta-statistic methods differ in what they monitor â€” they watch model performance or error trends, not the raw input data distributions.

---

# Dynamic Adapting Window Independence Drift Detection (DAWIDD)

Turns concept drift into an independence test

Note:

The whole philosophy behind DAWIDD is very simple but powerful:
if the data distribution does not change over time, then the data ğ‘‹ and time ğ‘‡ should be independent.
But if the data distribution does change â€” meaning a concept drift has occurred â€” then ğ‘‹ and ğ‘‡ become dependent.

--

# 1. Attach Time to Each Sample

Transform our data stream into a sequence of pairs, each data point is now represented as ($x_i$, $t_i$), where $x_i$ is the feature vector and $t_i$ is the timestamp

--

# 2. Maintain a Dynamically Adapting Window

This window, $W$, is constantly updated:

- Each time a new data point arrives, itâ€™s added to the window

- The window size is controlled by two parameters:

  - $n_{min}$: the minimum number of samples needed before we can reliably run a statistical test

  - $n_{max}$: the maximum number of samples allowed before we start dropping old ones.

Once the window exceeds $n_{max}$, we randomly delete some points rather than just discarding the oldest.

--

# 3. Testing Independence Between X and T

Once we have enough samples in our window (at least $n_{min}$), we perform a statistical test to check whether the data values $X$ are independent of the time values $T$.

- If the $H_0$ holds, meaning $X$ and $T$ are independent, thereâ€™s **no** drift
  - Keep adding **new** samples to the window

- If $H_0$ is reject, that means the distribution of $X$ has changed with time. So, a drift is detected
  - We signal a **drift event**
  - **Shrink** the window down to a small size, typically keeping only the last $n_{min}$ samples